import os
import glob
import pickle
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import pickle
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import precision_recall_curve
# Set random seed for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

print("Loading CIC-IDS2017 data...")

# Function to load and preprocess CIC-IDS2017 data
def load_cicids_data(data_dir='./data'):
    all_files = glob.glob(os.path.join(data_dir, '*.pcap_ISCX.csv'))
    
    if len(all_files) == 0:
        print("No CIC-IDS2017 .pcap_ISCX files found.")
        return None

    files_to_process = all_files[:2]  # Prevent memory overload
    dfs = []

    for file in files_to_process:
        print(f"Processing {file}...")
        df = pd.read_csv(file)
        df = df.dropna()

        # Replace infinities with large values
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        df[numeric_cols] = df[numeric_cols].replace([np.inf, -np.inf], np.nan)
        for col in numeric_cols:
            max_val = df[col].max()
            df[col] = df[col].fillna(max_val * 1000 if not pd.isna(max_val) else 0)

        dfs.append(df)

    # Combine and standardize
    full_df = pd.concat(dfs, ignore_index=True)
    full_df.columns = full_df.columns.str.strip()  # Clean column names

    if 'Label' in full_df.columns:
        full_df.rename(columns={'Label': 'label'}, inplace=True)
    elif ' Label' in full_df.columns:
        full_df.rename(columns={' Label': 'label'}, inplace=True)

    full_df['label'] = full_df['label'].apply(lambda x: 0 if x == 'BENIGN' else 1)

    return full_df

# Load dataset
cicids_df = load_cicids_data()

# Selected features
common_features = [
    'Total Length of Fwd Packets', 'Average Packet Size', 'Flow Duration', 
    'Flow Packets/s', 'Flow Bytes/s', 'Fwd PSH Flags', 'Bwd PSH Flags', 
    'SYN Flag Count', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'label'
]
print(f"Updated common features: {common_features}")

# Strip columns again just to be sure
cicids_df.columns = cicids_df.columns.str.strip()

# Subset and clean
combined_df = cicids_df[common_features]
combined_df = combined_df.fillna(0)

# Extract features & labels
X = combined_df.drop(columns=['label'])
y = combined_df['label']
print(f"Final dataset shape: {X.shape}")

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Save the scaler
with open("scaler_combined.pkl", "wb") as f:
    pickle.dump(scaler, f)

# --- NEW: Convert to sequences for LSTM ---
sequence_length = 10

X_seq = []
y_seq = []

for i in range(len(X_scaled) - sequence_length):
    X_seq.append(X_scaled[i:i + sequence_length])
    y_seq.append(y.iloc[i + sequence_length])  # Use the label *after* the sequence

X_seq = np.array(X_seq)
y_seq = np.array(y_seq)

print(f"Sequence shape: {X_seq.shape}, Labels: {y_seq.shape}")

# Split sequence data
X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(
    X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq
)
X_train_seq, X_val_seq, y_train_seq, y_val_seq = train_test_split(
    X_train_seq, y_train_seq, test_size=0.2, random_state=42, stratify=y_train_seq
)

# Final dataset shapes for model
print("Train shape:", X_train_seq.shape)
print("Val shape:", X_val_seq.shape)
print("Test shape:", X_test_seq.shape)
# Build LSTM model
print("Building LSTM model...")

model = Sequential([
    LSTM(128, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2]), return_sequences=True),
    Dropout(0.2),
    LSTM(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()
print("Training Data Class Distribution:")
print(y_train.value_counts())  # Count of normal (0) and attack (1) samples

print("Training the model...")

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', patience=3, restore_best_weights=True
)

history = model.fit(
    X_train_seq, y_train_seq,
    epochs=10,
    batch_size=64,
    validation_data=(X_val_seq, y_val_seq),
    callbacks=[early_stopping]
)
# Save the model
model.save("../ml_model/lstm_model_combined.keras")  # Preferred format

# Evaluate on test set
print("Evaluating on test set...")
y_pred_prob = model.predict(X_test_seq)

precision, recall, thresholds = precision_recall_curve(y_val_seq, model.predict(X_val_seq))
optimal_idx = np.argmax(2 * (precision * recall) / (precision + recall + 1e-9))  # F1
best_threshold = thresholds[optimal_idx]
print("Best threshold based on F1:", best_threshold)

y_pred = (y_pred_prob > best_threshold).astype(int).reshape(-1)
y_test_seq = np.array(y_test_seq).reshape(-1)  # Make sure y_test is also flat
accuracy = accuracy_score(y_test_seq, y_pred)
print(f"Test accuracy: {accuracy:.4f}")

# Save feature names
with open("feature_names_combined.pkl", "wb") as f:
    pickle.dump(X.columns.tolist(), f)

print("Model and scaler saved successfully! üöÄ")
# Make sure lengths match
min_len = min(len(y_test_seq), len(y_pred))
y_test_seq = y_test_seq[:min_len]
y_pred = y_pred[:min_len]

# Plot confusion matrix
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test_seq, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Normal', 'Attack'], 
            yticklabels=['Normal', 'Attack'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()
# 11. Save the model and related artifacts
model.save('../ml_model/lstm_model_combined.keras')
print("‚úÖ Model saved as 'lstm_model_combined.keras'")

with open('../ml_model/scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

with open('../ml_model/feature_names.pkl', 'wb') as f:
    pickle.dump(X.columns.tolist(), f)

# 12. Test on new data (simulated here with a sample from test set)
print("\nüß™ Testing on sample data...")

# Take a small sample from test set to simulate new data
sample_size = 100
sample_indices = np.random.choice(X_test_seq.shape[0], sample_size, replace=False)
X_sample_seq = X_test_seq[sample_indices]
y_sample = y_test_seq[sample_indices]  # ‚úÖ Fixed: use numpy-style indexing

# Predict
y_sample_pred_prob = model.predict(X_sample_seq)
y_sample_pred = (y_sample_pred_prob > best_threshold).astype(int).reshape(-1)

print(f"Sample test accuracy: {accuracy_score(y_sample, y_sample_pred):.4f}")
print("\nSample Classification Report:")
print(classification_report(y_sample, y_sample_pred, target_names=["Normal", "Attack"]))

# 13. Test prediction for a known attack sample from validation set
attack_indices = np.where(y_val_seq == 1)[0]
if len(attack_indices) > 0:
    sample = X_val_seq[attack_indices[0]]
    pred = model.predict(sample[np.newaxis, :, :])
    print(f"Prediction for known attack (probability): {pred[0][0]:.4f}")
else:
    print("No attack samples found in validation set for demonstration.")
# 11. Save the model and supporting files
model.save('../ml_model/lstm_model_combined.keras') 
print("‚úÖ Model saved as 'lstm_model_combined.keras'")

with open('../ml_model/scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

with open('../ml_model/feature_names.pkl', 'wb') as f:
    pickle.dump(X.columns.tolist(), f)

# 12. Test on new data (simulated here with a sample from test set)
print("\nüß™ Testing on sample data...")

# Take a small random sample from the test set
sample_size = 100
sample_indices = np.random.choice(X_test_seq.shape[0], sample_size, replace=False)
X_sample_seq = X_test_seq[sample_indices]
y_sample = y_test_seq[sample_indices]  # ‚úÖ FIXED: Use NumPy-style indexing

# Predict probabilities and apply threshold
y_sample_pred_prob = model.predict(X_sample_seq)
y_sample_pred = (y_sample_pred_prob > best_threshold).astype(int).reshape(-1)

# Evaluate on sample
print(f"Sample test accuracy: {accuracy_score(y_sample, y_sample_pred):.4f}")
print("\nSample Classification Report:")
print(classification_report(y_sample, y_sample_pred, target_names=["Normal", "Attack"]))

# 13. Predict a known attack sample from validation set
attack_indices = np.where(y_val_seq == 1)[0]
if attack_indices.size > 0:
    sample = X_val_seq[attack_indices[0]]
    pred = model.predict(sample[np.newaxis, :, :])
    print(f"Prediction for known attack (probability): {pred[0][0]:.4f}")
else:
    print("‚ö†Ô∏è No attack samples found in validation set.")
